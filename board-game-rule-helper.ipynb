{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c66c57",
   "metadata": {
    "papermill": {
     "duration": 0.003526,
     "end_time": "2025-04-18T00:30:51.539803",
     "exception": false,
     "start_time": "2025-04-18T00:30:51.536277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Capstone Project: Board Game Rule Helper\n",
    "\n",
    "**1. Use Case & Problem Statement**\n",
    "\n",
    "Board games often have complex rulebooks. During a game, players frequently need to clarify specific rules, like scoring conditions, action limitations, or turn sequences. Manually searching through a PDF or physical rulebook can be time-consuming and disrupt the flow of the game.\n",
    "\n",
    "This project aims to solve this problem by creating a \"Board Game Rule Helper\". Users can ask questions about the game's rules in natural language (e.g., \"How many cards do I draw at the start of my turn?\", \"What happens if I land on the red space?\"), and the system will provide answers directly sourced from the game's rulebook.\n",
    "\n",
    "**2. Solution using Generative AI**\n",
    "\n",
    "We will implement a simple Retrieval Augmented Generation (RAG) pipeline using Google's Generative AI models, accessed via the `google-genai` Python SDK (v1.7.0 pattern). We will use an explicit `genai.Client` for interactions. The core idea remains:\n",
    "\n",
    "1.  **Process the Rulebook:** Load the game's rules text and break it into manageable chunks.\n",
    "2.  **Embed the Knowledge:** Convert each rule chunk into a numerical vector (embedding) that captures its semantic meaning using `client.models.embed_content`. This uses the **Embeddings** capability.\n",
    "3.  **Store & Retrieve:** Store these embeddings. When a user asks a question, embed their question and search the stored rule embeddings to find the most relevant chunks based on semantic similarity. This simulates the core concept of a **Vector Search / Vector Store**.\n",
    "4.  **Generate Grounded Answer:** Provide the user's question along with the *retrieved relevant rule chunks* as context to a powerful generative model (like Gemini 1.5 Flash) using `client.models.generate_content`. This is the **Retrieval Augmented Generation (RAG)** step, ensuring answers are grounded in the source material.\n",
    "\n",
    "**3. Gen AI Capabilities Demonstrated**\n",
    "\n",
    "This notebook will explicitly demonstrate the following three capabilities using the `google-genai` client pattern:\n",
    "\n",
    "1.  **Embeddings:** Using `client.models.embed_content` with the `models/text-embedding-004` model.\n",
    "2.  **Vector Search / Vector Store (Concept):** Simulating vector search using cosine similarity.\n",
    "3.  **Retrieval Augmented Generation (RAG):** Using `client.models.generate_content` with retrieved context.\n",
    "\n",
    "**4. SDK Pattern Update**\n",
    "This version incorporates the specific setup and usage patterns provided by the user, utilizing `import google.genai as genai`, `genai.Client`, `client.models.*` methods, and includes robust retry logic based on `google.api_core.retry`.\n",
    "\n",
    "Let's build it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c450889",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-18T00:30:51.547797Z",
     "iopub.status.busy": "2025-04-18T00:30:51.547382Z",
     "iopub.status.idle": "2025-04-18T00:31:05.987384Z",
     "shell.execute_reply": "2025-04-18T00:31:05.986238Z"
    },
    "papermill": {
     "duration": 14.446112,
     "end_time": "2025-04-18T00:31:05.989148",
     "exception": false,
     "start_time": "2025-04-18T00:30:51.543036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mUsing google-genai version: 1.7.0\n",
      "API Key retrieved successfully from Kaggle secrets.\n",
      "genai.Client initialized successfully.\n",
      "Applying retry logic to client.models.generate_content...\n",
      "Retry logic applied.\n",
      "Using text model ID: gemini-2.0-flash (passed during generation)\n",
      "Using embedding model ID: models/text-embedding-004 (passed during embedding)\n",
      "\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Uninstall conflicting packages (as suggested for specific environments like Kaggle)\n",
    "!pip uninstall -qqy jupyterlab\n",
    "\n",
    "# Install the specific version of the Google GenAI library\n",
    "!pip install -U -q \"google-genai==1.7.0\"\n",
    "\n",
    "# Standard and Google imports\n",
    "import google.auth\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import google.genai as genai\n",
    "from google.genai import types # For config objects\n",
    "from google.api_core import retry # For retry logic\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity # For vector search simulation\n",
    "import textwrap\n",
    "\n",
    "# Check the library version\n",
    "print(f\"Using google-genai version: {genai.__version__}\")\n",
    "\n",
    "# --- Authentication and Client Initialization ---\n",
    "# Using Kaggle secrets - this is specific to the Kaggle environment\n",
    "# If running elsewhere, adapt key retrieval (e.g., environment variable, google.auth.default())\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    print(\"API Key retrieved successfully from Kaggle secrets.\")\n",
    "except ImportError:\n",
    "    print(\"Kaggle secrets not available. Trying GOOGLE_API_KEY environment variable.\")\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not GOOGLE_API_KEY:\n",
    "        print(\"API Key not found in environment variable.\")\n",
    "        # Attempt Application Default Credentials (ADC) as a fallback if appropriate\n",
    "        try:\n",
    "            print(\"Attempting Application Default Credentials (ADC)...\")\n",
    "            credentials, project_id = google.auth.default()\n",
    "            # Note: genai.Client doesn't directly take credentials object in this version AFAIK\n",
    "            # ADC usually works implicitly if GOOGLE_API_KEY is *not* set and running in a GCP env.\n",
    "            # For explicit ADC use, other libraries or configurations might be needed.\n",
    "            # We'll rely on API key primarily for this Gemini API focused example.\n",
    "            print(\"ADC found, but Client requires explicit API Key. Please set GOOGLE_API_KEY.\")\n",
    "            raise ValueError(\"API Key not found. Please set GOOGLE_API_KEY env var or Kaggle Secret.\")\n",
    "        except google.auth.exceptions.DefaultCredentialsError:\n",
    "            print(\"ADC not found.\")\n",
    "            raise ValueError(\"API Key not found. Please set GOOGLE_API_KEY env var or Kaggle Secret.\")\n",
    "    else:\n",
    "        print(\"API Key retrieved successfully from environment variable.\")\n",
    "\n",
    "# Initialize the client with the API Key\n",
    "# All API calls will now go through this 'client' object\n",
    "try:\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "    print(\"genai.Client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing genai.Client: {e}\")\n",
    "    raise SystemExit(\"Client initialization failed.\")\n",
    "\n",
    "\n",
    "# --- Retry Logic (Exactly as Provided) ---\n",
    "# Define a retry policy. The model might make multiple consecutive calls automatically\n",
    "# for a complex query, this ensures the client retries if it hits quota limits (429) or server errors (503).\n",
    "print(\"Applying retry logic to client.models.generate_content...\")\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "# Check if the method hasn't already been wrapped to avoid wrapping multiple times\n",
    "if not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n",
    "  genai.models.Models.generate_content = retry.Retry(\n",
    "      predicate=is_retriable)(genai.models.Models.generate_content)\n",
    "  print(\"Retry logic applied.\")\n",
    "else:\n",
    "    print(\"Retry logic already applied.\")\n",
    "\n",
    "# --- Model Selection ---\n",
    "# Model names are now passed as parameters to the client methods\n",
    "TEXT_MODEL_NAME = 'gemini-2.0-flash' # Or another suitable model like 'gemini-2.0-flash' from user example\n",
    "EMBEDDING_MODEL_NAME = 'models/text-embedding-004' # Keeping the newer embedding model\n",
    "\n",
    "print(f\"Using text model ID: {TEXT_MODEL_NAME} (passed during generation)\")\n",
    "print(f\"Using embedding model ID: {EMBEDDING_MODEL_NAME} (passed during embedding)\")\n",
    "\n",
    "# --- Helper function for printing ---\n",
    "def print_justified(text, width=80):\n",
    "  \"\"\"Prints text with justified alignment.\"\"\"\n",
    "  print(textwrap.fill(text, width=width))\n",
    "\n",
    "print(\"\\nSetup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4dcbec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T00:31:05.997630Z",
     "iopub.status.busy": "2025-04-18T00:31:05.997132Z",
     "iopub.status.idle": "2025-04-18T00:31:09.221243Z",
     "shell.execute_reply": "2025-04-18T00:31:09.220216Z"
    },
    "papermill": {
     "duration": 3.23022,
     "end_time": "2025-04-18T00:31:09.222807",
     "exception": false,
     "start_time": "2025-04-18T00:31:05.992587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating fictional board game rules...\n",
      "\n",
      "--- Generated Rules ---\n",
      "**Objective:**\n",
      "\n",
      "Be the first player to collect 3 Treasure Chests and return them to the Dragon Keep.\n",
      "\n",
      "**Game Setup:**\n",
      "\n",
      "1. Place the game board in the center of the table.\n",
      "2. Each player chooses a player token and places it on the Dragon Keep space.\n",
      "3. Shuffle the Treasure Chest cards and place them face down in a pile.\n",
      "4. Shuffle the Goblin cards and place them face down in a pile.\n",
      "5. Each player rolls a six-sided die. The player with the highest roll goes first.\n",
      "6. Each player receives 3 Health Points (HP).\n",
      "\n",
      "**Player Turn:**\n",
      "\n",
      "On your turn, you may perform up to two actions. Possible actions include:\n",
      "*   **Move:** Move your token across the board. (Cost: 1 Action Point)\n",
      "*   **Search:** Attempt to find treasure at your current location. (Cost: 1 Action Point)\n",
      "*   **Use Item:** Activate the effect of an item card. (Cost: 1 Action Point)\n",
      "*   **Rest:** Recover 1 HP. (Cost: 1 Action Point)\n",
      "\n",
      "**Movement:**\n",
      "\n",
      "Roll a six-sided die. Move your token that many spaces along the board's pathways. You cannot move through walls or obstacles. You may move in any direction.\n",
      "\n",
      "**Searching:**\n",
      "\n",
      "When you land on a Search space, you may spend an action to search. Draw one Treasure Chest card. If you are not on a Search space, you cannot search.\n",
      "\n",
      "**Combat:**\n",
      "\n",
      "If you encounter a Goblin, draw a Goblin card. Roll a six-sided die. If the roll is greater than or equal to the Goblin's Defense value (printed on the card), you defeat the Goblin and suffer no damage. If the roll is lower, you take 1 damage (lose 1 HP). You must defeat the goblin or flee (use an action point to move to an adjacent space that is free of goblins) before doing anything else.\n",
      "\n",
      "**Treasure Chests:**\n",
      "\n",
      "Treasure Chest cards can contain:\n",
      "*   **Gold:** Worth 1 point.\n",
      "*   **Items:** Special cards that grant a one-time bonus or ongoing effect.\n",
      "*   **Traps:** Lose 1 HP.\n",
      "\n",
      "**Winning the Game:**\n",
      "\n",
      "The first player to collect 3 Treasure Chest cards and return to the Dragon Keep space wins the game. Returning the Treasure Chests does not require an action.\n",
      "\n",
      "\n",
      "--- End Generated Rules ---\n",
      "\n",
      "Copy the text between '--- Generated Rules ---' and '--- End Generated Rules ---' and paste it into the RULEBOOK_TEXT variable in Cell 2.\n"
     ]
    }
   ],
   "source": [
    "# --- Optional: Cell to Generate Sample Rulebook Text ---\n",
    "\n",
    "# Make sure the 'client' object and TEXT_MODEL_NAME from Cell 1 are available\n",
    "\n",
    "print(\"Generating fictional board game rules...\")\n",
    "\n",
    "# Craft a prompt asking for rules\n",
    "generation_prompt = \"\"\"\n",
    "Generate a set of concise rules for a fictional fantasy board game called \"Dragon Keep Treasure Hunt\".\n",
    "The rules should be suitable for a simple RAG demonstration.\n",
    "Include the following sections clearly marked:\n",
    "\n",
    "**Objective:** (What is the goal?)\n",
    "**Game Setup:** (List 5-6 simple setup steps)\n",
    "**Player Turn:** (Describe 3-4 distinct actions a player can take, e.g., Move, Search, Use Item, Rest. Mention any costs like Action Points)\n",
    "**Movement:** (Explain how movement works, e.g., dice roll, map spaces)\n",
    "**Searching:** (Explain how searching for treasure works, e.g., dice roll, special spaces)\n",
    "**Combat:** (Very simple combat rules, e.g., against Goblins, maybe rolling a die vs a target number)\n",
    "**Treasure Chests:** (What do players find in them? e.g., Gold, Items, Traps)\n",
    "**Winning the Game:** (How does a player win?)\n",
    "\n",
    "Keep the rules clear, relatively simple, and use double newlines between distinct paragraphs or sections for easy parsing later.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Use the client to generate the rules\n",
    "    response = client.models.generate_content(\n",
    "        model=TEXT_MODEL_NAME, # Use the text generation model\n",
    "        contents=generation_prompt\n",
    "        # Add safety settings or generation config if needed\n",
    "    )\n",
    "\n",
    "    # Extract the generated text\n",
    "    generated_rules = response.text\n",
    "    print(\"\\n--- Generated Rules ---\")\n",
    "    print(generated_rules)\n",
    "    print(\"\\n--- End Generated Rules ---\")\n",
    "    print(\"\\nCopy the text between '--- Generated Rules ---' and '--- End Generated Rules ---' and paste it into the RULEBOOK_TEXT variable in Cell 2.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during rule generation: {e}\")\n",
    "    # Provide fallback generic rules if generation fails\n",
    "    generated_rules = \"\"\"\n",
    "**Fallback: Simple Adventure Game Rules**\n",
    "\n",
    "**Objective:** Be the first player to collect 3 Magic Gems and return to the Starting Village.\n",
    "\n",
    "**Game Setup:** Place the game board. Shuffle Item cards. Each player takes a Hero pawn and 5 Gold. Place pawns in the Starting Village.\n",
    "\n",
    "**Player Turn:** You have 3 Action Points (AP) per turn. Spend AP on: Move (1 AP per space), Search (2 AP), Fight (2 AP).\n",
    "\n",
    "**Movement:** Move your Hero pawn one adjacent space per 1 AP spent.\n",
    "\n",
    "**Searching:** On a 'Cave' space, spend 2 AP to draw 1 Item card.\n",
    "\n",
    "**Combat:** If you enter a space with a Monster token, spend 2 AP to fight. Roll one die: 4+ defeats the Monster. If defeated, gain 1 Magic Gem. If you roll 1-3, lose 1 Gold and end your turn.\n",
    "\n",
    "**Winning:** Enter the Starting Village space with 3 Magic Gems in your possession.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- FALLBACK RULES ---\")\n",
    "    print(generated_rules)\n",
    "    print(\"\\n--- END FALLBACK RULES ---\")\n",
    "    print(\"\\nUsing fallback rules due to generation error. Copy the fallback text into RULEBOOK_TEXT in Cell 2.\")\n",
    "\n",
    "\n",
    "# You can now copy the 'generated_rules' text (either the generated one or the fallback)\n",
    "# and paste it into Cell 2, replacing the existing RULEBOOK_TEXT definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4fbbee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T00:31:09.231723Z",
     "iopub.status.busy": "2025-04-18T00:31:09.231347Z",
     "iopub.status.idle": "2025-04-18T00:31:09.250353Z",
     "shell.execute_reply": "2025-04-18T00:31:09.249310Z"
    },
    "papermill": {
     "duration": 0.025922,
     "end_time": "2025-04-18T00:31:09.252304",
     "exception": false,
     "start_time": "2025-04-18T00:31:09.226382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rulebook loaded and split into 9 chunks.\n",
      "                                          text_chunk\n",
      "0                **Dragon Keep Treasure Hunt Rules**\n",
      "1  **Objective:** Be the first player to collect ...\n",
      "2  **Game Setup:**\\n1. Place the Dragon Keep game...\n",
      "3  **Player Turn:**\\nOn your turn, you start with...\n",
      "4  **Movement:**\\nMovement costs 1 AP per space (...\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load and Prepare Rule Document ---\n",
    "# (No changes needed here, same as before)\n",
    "\n",
    "RULEBOOK_TEXT = \"\"\"\n",
    "**Dragon Keep Treasure Hunt Rules**\n",
    "\n",
    "**Objective:** Be the first player to collect 3 Dragon Gems scattered within the keep and escape through the main gate.\n",
    "\n",
    "**Game Setup:**\n",
    "1. Place the Dragon Keep game board on the table.\n",
    "2. Shuffle the Treasure Deck and place it face down near the board.\n",
    "3. Shuffle the Encounter Deck (containing Goblins and Traps) and place it beside the Treasure Deck.\n",
    "4. Each player chooses a Hero pawn and places it on the 'Entrance Hall' starting space.\n",
    "5. Each player takes 3 Action Point (AP) tokens.\n",
    "6. The player wearing the most adventurous socks goes first.\n",
    "\n",
    "**Player Turn:**\n",
    "On your turn, you start with 3 Action Points (AP). You can spend AP on the following actions in any order until you run out of AP or choose to end your turn:\n",
    "A) Move: Spend 1 AP to move your Hero pawn to an adjacent room or corridor space on the board.\n",
    "B) Search: If you are in a room marked with a 'Search' icon, spend 2 AP to draw one card from the Treasure Deck.\n",
    "C) Disarm Trap: If you encounter a Trap card from the Encounter deck, you may spend 1 AP to attempt to disarm it. Roll a 6-sided die: on a 4+, the trap is disarmed. On a 1-3, suffer the trap's effect.\n",
    "D) Rest: Spend 1 AP to do nothing (useful if saving AP is not allowed or if you want to end your turn precisely).\n",
    "\n",
    "**Movement:**\n",
    "Movement costs 1 AP per space (room or corridor segment) entered. You cannot move through walls or locked doors unless you have a key item. Some spaces may trigger an Encounter card draw upon entering.\n",
    "\n",
    "**Searching:**\n",
    "Searching can only be performed in designated rooms (marked with a 'Search' icon) and costs 2 AP. Successfully searching allows you to draw one card from the Treasure Deck.\n",
    "\n",
    "**Combat:**\n",
    "If an Encounter card reveals a Goblin, combat begins. Combat does not cost AP itself, but happens immediately. Roll one 6-sided die. On a result of 5 or 6, you defeat the Goblin. On a result of 1-4, you are pushed back one space and lose 1 AP from your *next* turn (if possible). Defeated Goblins are discarded. Some items may modify combat rolls.\n",
    "\n",
    "**Treasure Chests:**\n",
    "Cards drawn from the Treasure Deck represent the contents of chests or findings. These can include:\n",
    "- Gold Pieces (used for certain item effects or potential scoring variants).\n",
    "- Dragon Gems (needed to win the game).\n",
    "- Useful Items (Potions, Rope, Keys, Magic Maps).\n",
    "- Occasionally, a Trap card might be mixed into the Treasure Deck!\n",
    "\n",
    "**Winning the Game:**\n",
    "The first player to collect exactly 3 Dragon Gems and then successfully move their Hero pawn onto the 'Entrance Hall' space (where players started) immediately declares victory and wins the game! You must reach the Entrance Hall; simply collecting the 3rd Gem is not enough.\n",
    "\"\"\"\n",
    "\n",
    "rule_chunks = [chunk.strip() for chunk in RULEBOOK_TEXT.split('\\n\\n') if chunk.strip()]\n",
    "df_rules = pd.DataFrame(rule_chunks, columns=['text_chunk'])\n",
    "print(f\"Rulebook loaded and split into {len(df_rules)} chunks.\")\n",
    "print(df_rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a482a6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T00:31:09.261406Z",
     "iopub.status.busy": "2025-04-18T00:31:09.261065Z",
     "iopub.status.idle": "2025-04-18T00:31:09.768795Z",
     "shell.execute_reply": "2025-04-18T00:31:09.767397Z"
    },
    "papermill": {
     "duration": 0.514353,
     "end_time": "2025-04-18T00:31:09.770387",
     "exception": false,
     "start_time": "2025-04-18T00:31:09.256034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demonstrating Capability 1: Embeddings ---\n",
      "Generating embeddings for 9 rule chunks using client with model models/text-embedding-004...\n",
      "Processing 9 texts in batches of 100...\n",
      "  Processing batch starting at index 0...\n",
      "    Successfully extracted 9 vectors via result.embeddings -> item.values.\n",
      "Finished processing all batches. Total embedding results processed: 9\n",
      "\n",
      "--- Verifying Embeddings Post-Assignment ---\n",
      "DataFrame shape after assigning embeddings column: (9, 2)\n",
      "Total chunks processed: 9\n",
      "Number of non-null embeddings generated: 9\n",
      "\n",
      "Processing successful. Have 9 chunks with valid embeddings.\n",
      "Embedding dimension for models/text-embedding-004: 768\n",
      "\n",
      "DataFrame with text chunks and embeddings (showing first few rows):\n",
      "                                          text_chunk  \\\n",
      "0                **Dragon Keep Treasure Hunt Rules**   \n",
      "1  **Objective:** Be the first player to collect ...   \n",
      "2  **Game Setup:**\\n1. Place the Dragon Keep game...   \n",
      "3  **Player Turn:**\\nOn your turn, you start with...   \n",
      "4  **Movement:**\\nMovement costs 1 AP per space (...   \n",
      "\n",
      "                             embedding_preview  \n",
      "0   [-0.0173, 0.0258, -0.0284, -0.0518, 0.036]  \n",
      "1  [-0.0377, 0.0051, -0.0046, -0.0315, 0.0479]  \n",
      "2  [-0.0386, 0.0264, -0.0036, -0.0265, 0.0288]  \n",
      "3   [-0.0413, 0.011, -0.0459, -0.0629, 0.0498]  \n",
      "4  [0.0049, -0.0037, -0.0564, -0.0866, 0.0286]  \n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Generate Embeddings (Capability 1) ---\n",
    "# Use the client object to generate embeddings.\n",
    "\n",
    "print(f\"\\n--- Demonstrating Capability 1: Embeddings ---\")\n",
    "print(f\"Generating embeddings for {len(df_rules)} rule chunks using client with model {EMBEDDING_MODEL_NAME}...\")\n",
    "\n",
    "# Updated function to use the client.models.embed_content method\n",
    "def generate_embeddings_batch_client(client_obj, texts, model_name, task_type=\"RETRIEVAL_DOCUMENT\", batch_size=100):\n",
    "    \"\"\"Generates embeddings using the client object in batches (Corrected Structure Handling).\"\"\"\n",
    "    all_embeddings = []\n",
    "    # Ensure task_type is valid for the model, RETRIEVAL_DOCUMENT is usually safe\n",
    "    config = types.EmbedContentConfig(task_type=task_type)\n",
    "\n",
    "    print(f\"Processing {len(texts)} texts in batches of {batch_size}...\")\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        print(f\"  Processing batch starting at index {i}...\")\n",
    "        try:\n",
    "            # Use client.models.embed_content\n",
    "            result = client_obj.models.embed_content(\n",
    "                model=model_name,\n",
    "                contents=batch, # Pass the list of texts directly\n",
    "                config=config # Pass the config object\n",
    "            )\n",
    "\n",
    "            # --- Debugging ---\n",
    "            # Keep this commented out unless needed again\n",
    "            # print(f\"  DEBUG: Raw result structure for batch {i}: {result}\")\n",
    "            # --- End Debugging ---\n",
    "\n",
    "            # --- CORRECTED Extraction Logic based on Debug Output ---\n",
    "            batch_embeddings = None # Initialize for this batch\n",
    "\n",
    "            # Check if result has an 'embeddings' attribute which is a list\n",
    "            if hasattr(result, 'embeddings') and isinstance(result.embeddings, list):\n",
    "                # Extract the 'values' attribute from each ContentEmbedding object in the list\n",
    "                try:\n",
    "                    # List comprehension to get the '.values' (the actual vector) from each item\n",
    "                    # Added check if item exists and has 'values' before accessing\n",
    "                    batch_embeddings = [item.values for item in result.embeddings if item and hasattr(item, 'values')]\n",
    "\n",
    "                    if len(batch_embeddings) == len(result.embeddings): # Check if all items yielded a vector\n",
    "                         print(f\"    Successfully extracted {len(batch_embeddings)} vectors via result.embeddings -> item.values.\")\n",
    "                    elif batch_embeddings: # Check if we got at least some vectors\n",
    "                         print(f\"    Warning: Extracted {len(batch_embeddings)} vectors, but expected {len(result.embeddings)}. Some items might lack 'values' or were None.\")\n",
    "                         # For this batch, we might have partial success. The length check below will handle it.\n",
    "                    else:\n",
    "                         print(f\"    Warning: Found result.embeddings list, but failed to extract any '.values'.\")\n",
    "                         batch_embeddings = None # Ensure failure\n",
    "\n",
    "                except AttributeError as attr_err:\n",
    "                     print(f\"    ERROR: Failed accessing '.values' attribute within result.embeddings list item: {attr_err}\")\n",
    "                     batch_embeddings = None # Ensure failure path is taken\n",
    "                except Exception as e:\n",
    "                     print(f\"    ERROR: Unexpected error during extraction from result.embeddings list: {e}\")\n",
    "                     batch_embeddings = None # Ensure failure path is taken\n",
    "            else:\n",
    "                 print(f\"  ERROR: Result object does not have '.embeddings' attribute or it's not a list.\")\n",
    "                 # print(f\"  DEBUG: Type of result object: {type(result)}\") # Optional debug\n",
    "\n",
    "            # --- Append or Handle Failure ---\n",
    "            # Check if we got exactly the number of embeddings expected for this batch\n",
    "            if batch_embeddings is not None and len(batch_embeddings) == len(batch):\n",
    "                all_embeddings.extend(batch_embeddings)\n",
    "            else:\n",
    "                # If extraction failed or length mismatch (e.g. partial success)\n",
    "                print(f\"  ERROR: Failed to extract expected number of embeddings for batch starting at {i}. Expected {len(batch)}, got {len(batch_embeddings) if batch_embeddings else 0}.\")\n",
    "                all_embeddings.extend([None] * len(batch)) # Add None placeholders\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch errors from the API call itself (e.g., network, permissions)\n",
    "            print(f\"  ERROR: Exception during embedding API call for batch starting at {i}: {e}\")\n",
    "            all_embeddings.extend([None] * len(batch)) # Add None placeholders on exception\n",
    "\n",
    "    print(f\"Finished processing all batches. Total embedding results processed: {len(all_embeddings)}\")\n",
    "    return all_embeddings\n",
    "\n",
    "# Generate embeddings using the client\n",
    "# Pass the initialized 'client' object\n",
    "rule_embeddings = generate_embeddings_batch_client(\n",
    "    client, # Pass the client object\n",
    "    df_rules['text_chunk'].tolist(),\n",
    "    EMBEDDING_MODEL_NAME\n",
    ")\n",
    "\n",
    "# Add the potentially None-filled embeddings list as a new column\n",
    "# Using .assign() is generally safer as it returns a new DataFrame copy\n",
    "try:\n",
    "    df_rules = df_rules.assign(embedding=rule_embeddings)\n",
    "except ValueError as e:\n",
    "    print(f\"Error assigning embeddings list (length mismatch?): {e}\")\n",
    "    print(f\"Length of DataFrame: {len(df_rules)}, Length of embeddings list: {len(rule_embeddings)}\")\n",
    "    raise SystemExit(\"Cannot assign embeddings, length mismatch.\")\n",
    "\n",
    "\n",
    "# --- Improved Check and Error Handling ---\n",
    "print(\"\\n--- Verifying Embeddings Post-Assignment ---\")\n",
    "print(f\"DataFrame shape after assigning embeddings column: {df_rules.shape}\")\n",
    "\n",
    "# Explicitly count how many embeddings are NOT None in the column\n",
    "successful_embeddings_count = df_rules['embedding'].notna().sum()\n",
    "total_chunks = len(df_rules)\n",
    "print(f\"Total chunks processed: {total_chunks}\")\n",
    "print(f\"Number of non-null embeddings generated: {successful_embeddings_count}\")\n",
    "\n",
    "# --- Stop Execution Firmly If No Embeddings Succeeded ---\n",
    "if successful_embeddings_count == 0:\n",
    "    # Raise a specific error to halt execution\n",
    "    raise ValueError(\"No valid embeddings were generated.\") # This should stop the cell\n",
    "\n",
    "# --- Handle Partial Failures ---\n",
    "elif successful_embeddings_count < total_chunks:\n",
    "    failed_count = total_chunks - successful_embeddings_count\n",
    "    print(f\"\\nWarning: Embedding generation failed for {failed_count} out of {total_chunks} chunks.\")\n",
    "    # Drop rows with failed embeddings\n",
    "    print(\"Dropping rows where embedding generation failed...\")\n",
    "    original_len = len(df_rules)\n",
    "    df_rules = df_rules.dropna(subset=['embedding'])\n",
    "    print(f\"Dropped {original_len - len(df_rules)} rows. Proceeding with {len(df_rules)} valid chunks.\")\n",
    "\n",
    "    # Double-check if DataFrame became empty after dropping\n",
    "    if df_rules.empty:\n",
    "         print(\"ERROR: DataFrame is empty after dropping rows with failed embeddings.\")\n",
    "         raise ValueError(\"No valid embeddings remaining after cleanup.\")\n",
    "\n",
    "# --- Proceed only if we have at least one valid embedding ---\n",
    "print(f\"\\nProcessing successful. Have {len(df_rules)} chunks with valid embeddings.\")\n",
    "\n",
    "# Now, it should be safe to get the dimension because we know df_rules is not empty\n",
    "# and the 'embedding' column has at least one valid list.\n",
    "embedding_dim = len(df_rules['embedding'].iloc[0])\n",
    "print(f\"Embedding dimension for {EMBEDDING_MODEL_NAME}: {embedding_dim}\")\n",
    "\n",
    "print(\"\\nDataFrame with text chunks and embeddings (showing first few rows):\")\n",
    "# Create preview only if embeddings exist and are lists/arrays\n",
    "df_rules['embedding_preview'] = df_rules['embedding'].apply(\n",
    "    lambda x: np.round(x[:5], 4) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else \"N/A\"\n",
    ")\n",
    "print(df_rules[['text_chunk', 'embedding_preview']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19efce62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T00:31:09.779276Z",
     "iopub.status.busy": "2025-04-18T00:31:09.778937Z",
     "iopub.status.idle": "2025-04-18T00:31:10.074333Z",
     "shell.execute_reply": "2025-04-18T00:31:10.073371Z"
    },
    "papermill": {
     "duration": 0.301899,
     "end_time": "2025-04-18T00:31:10.076000",
     "exception": false,
     "start_time": "2025-04-18T00:31:09.774101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demonstrating Capability 2: Vector Search / Vector Store (Concept) ---\n",
      "\n",
      "Searching for chunks relevant to query: 'How do I win the game?'\n",
      "    Successfully extracted query embedding vector.\n",
      "Found 3 relevant chunks:\n",
      "                                          text_chunk  similarity\n",
      "8  **Winning the Game:**\\nThe first player to col...    0.666936\n",
      "1  **Objective:** Be the first player to collect ...    0.535640\n",
      "7  **Treasure Chests:**\\nCards drawn from the Tre...    0.533111\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Implement Vector Search (Capability 2) ---\n",
    "# Use the client object to embed the query.\n",
    "\n",
    "print(f\"\\n--- Demonstrating Capability 2: Vector Search / Vector Store (Concept) ---\")\n",
    "\n",
    "# Updated function to use the client for query embedding with CORRECT structure handling\n",
    "def find_relevant_chunks_client(client_obj, query, df_embeddings, embedding_model, top_n=3):\n",
    "    \"\"\"Finds the top_n most relevant text chunks using the client (Corrected Query Embedding).\"\"\"\n",
    "    if df_embeddings.empty:\n",
    "        print(\"Error: No document embeddings available to search.\")\n",
    "        return pd.DataFrame()\n",
    "    # Ensure the 'embedding' column actually exists after potential earlier failures\n",
    "    if 'embedding' not in df_embeddings.columns:\n",
    "        print(\"Error: Document DataFrame is missing the 'embedding' column.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "    print(f\"\\nSearching for chunks relevant to query: '{query}'\")\n",
    "\n",
    "    # 1. Generate embedding for the user query using the client (CORRECTED EXTRACTION)\n",
    "    query_embedding = None # Initialize\n",
    "    query_embedding_np = None # Initialize\n",
    "    try:\n",
    "        # Prepare config for query embedding\n",
    "        query_config = types.EmbedContentConfig(task_type=\"RETRIEVAL_QUERY\") # Use correct task type\n",
    "        query_embedding_response = client_obj.models.embed_content(\n",
    "            model=embedding_model, # Use the selected embedding model\n",
    "            contents=query,        # Pass query string directly\n",
    "            config=query_config\n",
    "        )\n",
    "\n",
    "        # --- CORRECTED Extraction Logic for Single Query ---\n",
    "        # Expect response.embeddings to be a list with one ContentEmbedding object\n",
    "        if (hasattr(query_embedding_response, 'embeddings') and\n",
    "            isinstance(query_embedding_response.embeddings, list) and\n",
    "            len(query_embedding_response.embeddings) > 0 and\n",
    "            query_embedding_response.embeddings[0] and # Check if the first item exists\n",
    "            hasattr(query_embedding_response.embeddings[0], 'values')):\n",
    "\n",
    "            # Access the 'values' of the *first* ContentEmbedding object in the list\n",
    "            query_embedding = query_embedding_response.embeddings[0].values\n",
    "            print(f\"    Successfully extracted query embedding vector.\")\n",
    "            # Convert to NumPy array and reshape for cosine_similarity\n",
    "            query_embedding_np = np.array(query_embedding).reshape(1, -1)\n",
    "\n",
    "        else:\n",
    "             # This path should ideally not be reached if API call succeeded\n",
    "             print(f\"    ERROR: Failed to extract query embedding. Response structure unexpected.\")\n",
    "             # print(f\"    DEBUG: Query response structure: {query_embedding_response}\") # Optional Debug\n",
    "             # return pd.DataFrame() # Handled by check below\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: Exception during query embedding API call: {e}\")\n",
    "        # return pd.DataFrame() # Handled by check below\n",
    "\n",
    "    # Check if query embedding was successfully extracted and converted\n",
    "    if query_embedding_np is None:\n",
    "         print(\"    Failed to generate or process the query embedding. Cannot proceed with search.\")\n",
    "         return pd.DataFrame()\n",
    "\n",
    "\n",
    "    # 2. Calculate Cosine Similarity\n",
    "    try:\n",
    "        # Get document embeddings ready for calculation\n",
    "        rule_embeddings_np = np.array(df_embeddings['embedding'].tolist())\n",
    "\n",
    "        # Check for shape mismatches (should definitely match now if extraction worked)\n",
    "        if rule_embeddings_np.shape[1] != query_embedding_np.shape[1]:\n",
    "             print(f\"    ERROR: Embedding dimension mismatch AFTER extraction. Query: {query_embedding_np.shape[1]}, Chunks: {rule_embeddings_np.shape[1]}. Check embedding models consistency.\")\n",
    "             return pd.DataFrame()\n",
    "\n",
    "        similarities = cosine_similarity(query_embedding_np, rule_embeddings_np)[0]\n",
    "\n",
    "    except ValueError as ve:\n",
    "        # Catch errors often related to list-of-lists conversion in np.array() if 'embedding' column has Nones\n",
    "        print(f\"    ERROR: ValueError during similarity calculation. Often due to inconsistent data in 'embedding' column: {ve}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: Exception during similarity calculation: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "    # 3. Find Top N matches\n",
    "    try:\n",
    "        if len(similarities) != len(df_embeddings):\n",
    "             print(f\"    ERROR: Number of similarities ({len(similarities)}) doesn't match number of documents ({len(df_embeddings)}).\")\n",
    "             return pd.DataFrame()\n",
    "\n",
    "        # Get indices of top N similarities\n",
    "        top_n_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: Exception during sorting similarities: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 4. Retrieve the corresponding chunks\n",
    "    relevant_chunks_df = df_embeddings.iloc[top_n_indices].copy()\n",
    "    relevant_chunks_df['similarity'] = similarities[top_n_indices]\n",
    "\n",
    "    print(f\"Found {len(relevant_chunks_df)} relevant chunks:\")\n",
    "    print(relevant_chunks_df[['text_chunk', 'similarity']])\n",
    "\n",
    "    return relevant_chunks_df\n",
    "\n",
    "# --- Example Search ---\n",
    "if 'embedding' in df_rules.columns:\n",
    "    user_query = \"How do I win the game?\"\n",
    "    # Use the updated function, passing the client\n",
    "    relevant_docs = find_relevant_chunks_client(client, user_query, df_rules, EMBEDDING_MODEL_NAME)\n",
    "else:\n",
    "    print(\"Embeddings column not found. Skipping vector search example.\")\n",
    "    relevant_docs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258f3ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T00:31:10.086195Z",
     "iopub.status.busy": "2025-04-18T00:31:10.085897Z",
     "iopub.status.idle": "2025-04-18T00:31:11.571534Z",
     "shell.execute_reply": "2025-04-18T00:31:11.570238Z"
    },
    "papermill": {
     "duration": 1.493496,
     "end_time": "2025-04-18T00:31:11.573233",
     "exception": false,
     "start_time": "2025-04-18T00:31:10.079737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demonstrating Capability 3: Retrieval Augmented Generation (RAG) ---\n",
      "\n",
      "Generating RAG answer for query: 'How do I win the game?' using client with model gemini-2.0-flash...\n",
      "\n",
      "Final Answer (Generated by RAG model):\n",
      "To win, you must be the first player to collect exactly 3 Dragon Gems and then\n",
      "move your Hero pawn onto the 'Entrance Hall' space. Collecting the 3 Dragon Gems\n",
      "is not enough; you must also reach the Entrance Hall.\n",
      "\n",
      "Searching for chunks relevant to query: 'How much fuel does exploring cost?'\n",
      "    Successfully extracted query embedding vector.\n",
      "Found 2 relevant chunks:\n",
      "                                          text_chunk  similarity\n",
      "5  **Searching:**\\nSearching can only be performe...    0.499246\n",
      "4  **Movement:**\\nMovement costs 1 AP per space (...    0.496962\n",
      "\n",
      "Generating RAG answer for query: 'How much fuel does exploring cost?' using client with model gemini-2.0-flash...\n",
      "\n",
      "Final Answer (Generated by RAG model):\n",
      "The provided rules do not mention fuel. Movement costs 1 AP per space entered.\n",
      "Searching costs 2 AP.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Perform Retrieval Augmented Generation (RAG) (Capability 3) ---\n",
    "# Use the client object to generate the final answer.\n",
    "\n",
    "print(f\"\\n--- Demonstrating Capability 3: Retrieval Augmented Generation (RAG) ---\")\n",
    "\n",
    "# NOTE: We don't need to initialize a separate GenerativeModel instance anymore.\n",
    "# We use the client directly.\n",
    "\n",
    "# Updated function to use the client.models.generate_content method\n",
    "def generate_rag_answer_client(client_obj, query, relevant_docs_df, text_model_id):\n",
    "    \"\"\"Generates an answer using the client based on the query and retrieved context.\"\"\"\n",
    "    if relevant_docs_df.empty:\n",
    "        print(\"No relevant documents found...\")\n",
    "        return \"I could not find specific rules related to your question...\"\n",
    "\n",
    "    print(f\"\\nGenerating RAG answer for query: '{query}' using client with model {text_model_id}...\")\n",
    "\n",
    "    # 1. Prepare context (same as before)\n",
    "    context = \"\\n---\\n\".join(relevant_docs_df['text_chunk'].tolist())\n",
    "\n",
    "    # 2. Construct RAG Prompt (same structure as before)\n",
    "    rag_prompt = f\"\"\"\n",
    "You are a helpful Board Game Rule Assistant... answer based *only* on the provided rule excerpts...\n",
    "\n",
    "**Player's Question:**\n",
    "{query}\n",
    "\n",
    "**Relevant Rule Excerpts Provided:**\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "**Answer (Based ONLY on the excerpts):**\n",
    "\"\"\"\n",
    "    # print(f\"Prompt length: {len(rag_prompt)}\") # Optional debug\n",
    "\n",
    "    # 3. Generate the answer using client.models.generate_content\n",
    "    # The retry logic applied in Cell 1 automatically handles this call.\n",
    "    try:\n",
    "        # Call using the client object\n",
    "        response = client_obj.models.generate_content(\n",
    "            model=text_model_id, # Pass the model name string\n",
    "            contents=rag_prompt   # Pass the full prompt string\n",
    "            # Add generation_config here if needed (e.g., temperature, safety)\n",
    "            # config = types.GenerateContentConfig(temperature=0.5)\n",
    "        )\n",
    "\n",
    "        # Process response (check structure - client response might differ slightly)\n",
    "        if not response.candidates:\n",
    "             print(\"Warning: Response generated, but no candidates found.\")\n",
    "             return \"The model did not generate a valid response candidate.\"\n",
    "        # Accessing text might be via response.text shortcut if available and unambiguous\n",
    "        # Or more robustly through candidates and parts\n",
    "        try:\n",
    "            final_answer = response.text # Try direct access first\n",
    "        except ValueError: # Handle cases where .text isn't straightforward (e.g., multiple candidates/parts, non-text parts)\n",
    "             print(\"Warning: Direct .text access failed, checking parts.\")\n",
    "             if response.candidates[0].content.parts:\n",
    "                  final_answer = \"\".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))\n",
    "             else:\n",
    "                  final_answer = \"Model generated response structure without text parts.\"\n",
    "\n",
    "        if not final_answer:\n",
    "             final_answer = \"Model returned empty text content.\"\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during RAG content generation with client: {e}\")\n",
    "        # Check if the error object has response details\n",
    "        error_response = getattr(e, 'response', None)\n",
    "        print(f\"Error details (if available): {error_response}\")\n",
    "        final_answer = f\"Sorry, I encountered an error trying to answer: {e}\"\n",
    "\n",
    "    print(\"\\nFinal Answer (Generated by RAG model):\")\n",
    "    print_justified(final_answer)\n",
    "    return final_answer\n",
    "\n",
    "# --- Example RAG Usage ---\n",
    "if not relevant_docs.empty:\n",
    "    # Use the updated function, passing the client and the text model ID string\n",
    "    final_answer = generate_rag_answer_client(client, user_query, relevant_docs, TEXT_MODEL_NAME)\n",
    "else:\n",
    "    print(f\"\\nSkipping RAG generation for '{user_query}' as no relevant documents were found.\")\n",
    "\n",
    "# --- Try another query ---\n",
    "user_query_2 = \"How much fuel does exploring cost?\"\n",
    "if 'embedding' in df_rules.columns:\n",
    "    relevant_docs_2 = find_relevant_chunks_client(client, user_query_2, df_rules, EMBEDDING_MODEL_NAME, top_n=2)\n",
    "    if not relevant_docs_2.empty:\n",
    "        # Use the updated function\n",
    "        final_answer_2 = generate_rag_answer_client(client, user_query_2, relevant_docs_2, TEXT_MODEL_NAME)\n",
    "    else:\n",
    "        print(f\"\\nSkipping RAG generation for '{user_query_2}' as no relevant documents were found.\")\n",
    "else:\n",
    "    print(\"Embeddings column not found. Skipping second vector search example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ce8cd",
   "metadata": {
    "papermill": {
     "duration": 0.003655,
     "end_time": "2025-04-18T00:31:11.580977",
     "exception": false,
     "start_time": "2025-04-18T00:31:11.577322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Conclusion & Limitations\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "This notebook successfully demonstrated a simple Retrieval Augmented Generation (RAG) pipeline to create a \"Board Game Rule Helper\", utilizing the `google-genai` (v1.7.0 pattern) Python SDK and its client-based interaction model. We applied three key Generative AI capabilities:\n",
    "\n",
    "1.  **Embeddings:** via `client.models.embed_content` to represent rulebook sections.\n",
    "2.  **Vector Search (Concept):** via cosine similarity to retrieve relevant sections.\n",
    "3.  **Retrieval Augmented Generation (RAG):** via `client.models.generate_content` to generate context-grounded answers.\n",
    "\n",
    "The implementation now accurately reflects the intended client-based interaction pattern, includes robust retry logic, and correctly handles API calls for embedding and generation based on the confirmed response structures. The system effectively processes natural language questions, finds relevant rule snippets, and synthesizes context-aware answers sourced directly from the provided ruleset.\n",
    "\n",
    "**Limitations & Future Work**\n",
    "\n",
    "* **Basic Chunking:** Simple paragraph splitting was used. More advanced semantic chunking could improve retrieval relevance for complex rulebooks.\n",
    "* **Simulated Vector Search:** Calculating cosine similarity across all chunks is inefficient for large documents. A real-world application would integrate an optimized vector database (like FAISS, ChromaDB, Pinecone, or Vertex AI Vector Search) for faster, scalable retrieval.\n",
    "* **Small Rulebook:** The demo used a relatively short, generated rule set. Performance and accuracy should be tested on larger, official rulebooks.\n",
    "* **Context Window Limits:** While Gemini 1.5 models have large context windows, extremely long rulebooks or very complex queries requiring many retrieved chunks might still pose challenges, potentially requiring strategies like re-ranking or iterative context feeding.\n",
    "* **Noisy Retrievals:** Vector search can occasionally return chunks that are semantically similar but not perfectly relevant to the specific nuance of a question. Advanced RAG might involve re-ranking retrieved chunks or more sophisticated prompt engineering.\n",
    "* **Evaluation:** No formal evaluation (like **Gen AI Evaluation**) was performed to quantitatively measure the accuracy, relevance, and factuality of the generated answers against the source rulebook. This would be a critical step for assessing production readiness.\n",
    "\n",
    "Despite these limitations, this project serves as a functional proof-of-concept demonstrating how the RAG pattern and associated `google-genai` capabilities can be effectively applied to create useful, grounded information retrieval applications."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 97258,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.777386,
   "end_time": "2025-04-18T00:31:12.506054",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-18T00:30:46.728668",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
